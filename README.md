# nispa-WhisperApp

nispa-WhisperApp is a desktop application that allows you to transcribe audio and video files using the power of OpenAI's Whisper model, optimized for speed with `faster-whisper`. It provides a user-friendly interface to manage, view, and edit your transcriptions.

## âœ¨ Features

-   **High-Quality Transcription:** Utilizes `faster-whisper` for accurate and fast audio-to-text conversion.
-   **Multiple Model Sizes:** Supports different Whisper model sizes (e.g., tiny, medium) to balance speed and accuracy.
-   **File Management:** Upload and manage your audio/video files directly within the app.
-   **Transcription Editor:** A built-in editor to review and correct the generated transcriptions.
-   **GPU Acceleration:** Automatically detects and utilizes NVIDIA GPUs (via CUDA) for significantly faster processing.
-   **Web-Based UI:** A modern and responsive user interface built with React and TypeScript.

## ğŸ› ï¸ Tech Stack

-   **Backend:**
    -   Python
    -   Flask (or a similar Python web framework)
    -   `faster-whisper` for the core transcription engine
    -   SQLite for database management
-   **Frontend:**
    -   React
    -   TypeScript
    -   Vite
-   **Core Dependencies:**
    -   `ctranslate2`
    -   `librosa`
    -   `faster-whisper`

## ğŸš€ Getting Started

### Prerequisites

-   Python 3.11+
-   Node.js and npm
-   FFmpeg 
-   (Optional but Recommended) An NVIDIA GPU with CUDA installed for hardware acceleration.
 
### Installation

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/nispa/nispa-whisper
    cd nispa-whisper
    ```

2.  **Set up the environment:**
    Run the installation script to create a Python virtual environment and install all required dependencies.
    ```batch
    install_env.bat
    ```
    This will also install the necessary Node.js packages for the frontend.

### Running the Application

Once the installation is complete, you can start the application using the provided script:

```batch
run_app.bat
```

This command will launch the backend server and frontend application, which you can access in your web browser, typically at `http://localhost:5173`.

## ğŸ“ Project Structure

```
nispa-whisper/
â”œâ”€â”€ backend/            # Python backend (Flask/API)
â”‚   â”œâ”€â”€ app.py          # Main application entrypoint
â”‚   â”œâ”€â”€ database.py     # Database setup and models
â”‚   â”œâ”€â”€ audio/          # Audio processing modules
â”‚   â”œâ”€â”€ gpu/            # GPU detection logic
â”‚   â””â”€â”€ models/         # Whisper model wrapper
â”œâ”€â”€ frontend/           # React frontend application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/ # UI Components
â”‚   â”‚   â”œâ”€â”€ api.ts      # API communication
â”‚   â”‚   â””â”€â”€ App.tsx     # Main React component
â”‚   â””â”€â”€ vite.config.ts  # Vite configuration
â”œâ”€â”€ data/               # Application data
â”‚   â”œâ”€â”€ whisperapp.db   # SQLite database
â”‚   â”œâ”€â”€ cache/          # Cached media files
â”‚   â””â”€â”€ models/         # Downloaded whisper models
â”œâ”€â”€ install_env.bat     # Installation script
â”œâ”€â”€ run_app.bat         # Script to run the application
â””â”€â”€ README.md           # This file
```
